{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'tag', 'tag_id'],\n",
       "        num_rows: 3394\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'tag', 'tag_id'],\n",
       "        num_rows: 1009\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'tag', 'tag_id'],\n",
       "        num_rows: 1287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def read_wnut(file_path):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    raw_text = file_path.read_text().strip()\n",
    "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for doc in raw_docs:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in doc.split('\\n'):\n",
    "            if len(line.split('\\t'))  < 2:\n",
    "                continue\n",
    "            # print(line, len(line.split('\\t')))\n",
    "            token, tag = line.split('\\t')\n",
    "            tokens.append(token)\n",
    "            tags.append(tag)\n",
    "        token_docs.append(tokens)\n",
    "        tag_docs.append(tags)\n",
    "    return token_docs, tag_docs\n",
    "\n",
    "train_tokens, train_tags = read_wnut('wnut17train.conll')\n",
    "val_tokens, val_tags = read_wnut('emerging.dev.conll')\n",
    "test_tokens, test_tags = read_wnut('emerging.test.annotated')\n",
    "\n",
    "# total_tags = train_tags + val_tags + test_tags\n",
    "\n",
    "# unique_tags = set(tag for doc in total_tags for tag in doc)\n",
    "# tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "tag2id = {\n",
    "          'O': 0,\n",
    "          'B-person': 1,\n",
    "          'I-person': 2,\n",
    "          'B-location': 3,\n",
    "          'I-location': 4,\n",
    "          'B-corporation': 5,\n",
    "          'I-corporation': 6,\n",
    "          'B-product': 7,\n",
    "          'I-product': 8,\n",
    "          'B-creative-work': 9,\n",
    "          'I-creative-work': 10,\n",
    "          'B-group': 11,\n",
    "          'I-group': 12\n",
    "          }\n",
    "\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "\n",
    "train_tag_id = [[tag2id[tag] for tag in doc] for doc in train_tags]\n",
    "val_tag_id = [[tag2id[tag] for tag in doc] for doc in val_tags]\n",
    "test_tag_id = [[tag2id[tag] for tag in doc] for doc in test_tags]\n",
    "\n",
    "from datasets import  Dataset, DatasetDict\n",
    "\n",
    "train_data = {\n",
    "    'tokens': train_tokens,\n",
    "    'tag': train_tags,\n",
    "    'tag_id': train_tag_id,\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    'tokens': test_tokens,\n",
    "    'tag': test_tags,\n",
    "    'tag_id': test_tag_id,\n",
    "}\n",
    "\n",
    "validation_data = {\n",
    "    'tokens': val_tokens,\n",
    "    'tag': val_tags,\n",
    "    'tag_id': val_tag_id,\n",
    "}\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(validation_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "whole_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "whole_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels in int\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"tag_id\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"J1mb0o/bert-finetuned-ner-noval\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = whole_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=whole_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_val_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2tag,\n",
    "    label2id=tag2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "label_names = list(tag2id.keys())\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "metric.compute(predictions=[all_predictions], references=[all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [\"16\", \"32\"]\n",
    "learning_rate = [\"1e-5\", \"3e-5\", \"5e-5\"]\n",
    "\n",
    "for b in batch_size:\n",
    "    for lr in learning_rate:\n",
    "        model_checkpoint = f\"J1mb0o/bert-finetuned-batch{b}-lr{lr}\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "        data_collator = DataCollatorForTokenClassification(\n",
    "            tokenizer=tokenizer, return_tensors=\"tf\"\n",
    "        )\n",
    "        model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "            model_checkpoint,\n",
    "            id2label=id2tag,\n",
    "            label2id=tag2id,\n",
    "        )\n",
    "\n",
    "        print(f\"batch_size: {b}, learning_rate: {lr}\")\n",
    "        print(model_checkpoint)\n",
    "\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        for batch in tf_test_dataset:\n",
    "            logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            predictions = np.argmax(logits, axis=-1)\n",
    "            for prediction, label in zip(predictions, labels):\n",
    "                for predicted_idx, label_idx in zip(prediction, label):\n",
    "                    if label_idx == -100:\n",
    "                        continue\n",
    "                    all_predictions.append(label_names[predicted_idx])\n",
    "                    all_labels.append(label_names[label_idx])\n",
    "        print(metric.compute(predictions=[all_predictions], references=[all_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we found our best model we will dive a bit more into the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf93a24a300c45b88d29198824ca4bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3c1f7d91a4488eadcec4033382fd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7308d1ca20ea40a38da4c073a2d9490c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Some layers from the model checkpoint at J1mb0o/bert-finetuned-batch16-lr3e-5 were not used when initializing TFBertForTokenClassification: ['dropout_265']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at J1mb0o/bert-finetuned-batch16-lr3e-5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J1mb0o/bert-finetuned-batch16-lr3e-5\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "model_checkpoint = f\"J1mb0o/bert-finetuned-batch16-lr3e-5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "tokenized_datasets = whole_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=whole_dataset[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
    ")\n",
    "\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_val_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2tag,\n",
    "    label2id=tag2id,\n",
    ")\n",
    "\n",
    "print(model_checkpoint)\n",
    "label_names = list(tag2id.keys())\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the labels to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_predictions[0])\n",
    "# print(tag2id[all_predictions[0]])\n",
    "\n",
    "all_predictions_id = [tag2id[pred] for pred in all_predictions]\n",
    "all_labels_id = [tag2id[label] for label in all_labels]\n",
    "class_id = list(tag2id.values())\n",
    "# print(class_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                Precision            Recall               F1                  \n",
      "O                    0.9455               0.9964               0.9703              \n",
      "B-person             0.8498               0.4615               0.5982              \n",
      "I-person             0.8239               0.3007               0.4405              \n",
      "B-location           0.7054               0.5267               0.6031              \n",
      "I-location           0.7850               0.3544               0.4884              \n",
      "B-corporation        0.3396               0.2727               0.3025              \n",
      "I-corporation        0.3544               0.2105               0.2642              \n",
      "B-product            0.4390               0.1417               0.2143              \n",
      "I-product            0.5593               0.2758               0.3694              \n",
      "B-creative-work      0.7222               0.2746               0.3980              \n",
      "I-creative-work      0.6301               0.2081               0.3129              \n",
      "B-group              0.5870               0.1636               0.2559              \n",
      "I-group              0.5152               0.1405               0.2208              \n",
      "\n",
      "\n",
      "micro                0.9360               0.9360               0.9360              \n",
      "macro                0.6351               0.3329               0.4183              \n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate_predictions(y_pred, y_true, names_dict):\n",
    "    recall = metrics.recall_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "    precision = metrics.precision_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "\n",
    "    f1 = metrics.f1_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "\n",
    "    recall_micro = metrics.recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    recall_macro = metrics.recall_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "\n",
    "    precision_micro = metrics.precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    precision_macro = metrics.precision_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "\n",
    "    f1_micro = metrics.f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    f1_macro = metrics.f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    \n",
    "    print(f\"{'Label':<20} {'Precision':<20} {'Recall':<20} {'F1':<20}\")\n",
    "    for id, tag in zip( names_dict.values(), names_dict.keys()):\n",
    "        print(f\"{tag:<20} {precision[id]:<20.4f} {recall[id]:<20.4f} {f1[id]:<20.4f}\")\n",
    "    print('\\n')\n",
    "    print(f\"{'micro':<20} {precision_micro:<20.4f} {recall_micro:<20.4f} {f1_micro:<20.4f}\")\n",
    "    print(f\"{'macro':<20} {precision_macro:<20.4f} {recall_macro:<20.4f} {f1_macro:<20.4f}\")\n",
    "\n",
    "\n",
    "evaluate_predictions(all_predictions_id, all_labels_id, tag2id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
