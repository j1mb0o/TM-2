{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'tag', 'tag_id'],\n",
       "        num_rows: 3394\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'tag', 'tag_id'],\n",
       "        num_rows: 1009\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'tag', 'tag_id'],\n",
       "        num_rows: 1287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def read_wnut(file_path):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    raw_text = file_path.read_text().strip()\n",
    "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for doc in raw_docs:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in doc.split('\\n'):\n",
    "            if len(line.split('\\t'))  < 2:\n",
    "                continue\n",
    "            # print(line, len(line.split('\\t')))\n",
    "            token, tag = line.split('\\t')\n",
    "            tokens.append(token)\n",
    "            tags.append(tag)\n",
    "        token_docs.append(tokens)\n",
    "        tag_docs.append(tags)\n",
    "    return token_docs, tag_docs\n",
    "\n",
    "train_tokens, train_tags = read_wnut('wnut17train.conll')\n",
    "val_tokens, val_tags = read_wnut('emerging.dev.conll')\n",
    "test_tokens, test_tags = read_wnut('emerging.test.annotated')\n",
    "\n",
    "# total_tags = train_tags + val_tags + test_tags\n",
    "\n",
    "# unique_tags = set(tag for doc in total_tags for tag in doc)\n",
    "# tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "tag2id = {\n",
    "          'O': 0,\n",
    "          'B-person': 1,\n",
    "          'I-person': 2,\n",
    "          'B-location': 3,\n",
    "          'I-location': 4,\n",
    "          'B-corporation': 5,\n",
    "          'I-corporation': 6,\n",
    "          'B-product': 7,\n",
    "          'I-product': 8,\n",
    "          'B-creative-work': 9,\n",
    "          'I-creative-work': 10,\n",
    "          'B-group': 11,\n",
    "          'I-group': 12\n",
    "          }\n",
    "\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "\n",
    "train_tag_id = [[tag2id[tag] for tag in doc] for doc in train_tags]\n",
    "val_tag_id = [[tag2id[tag] for tag in doc] for doc in val_tags]\n",
    "test_tag_id = [[tag2id[tag] for tag in doc] for doc in test_tags]\n",
    "\n",
    "from datasets import  Dataset, DatasetDict\n",
    "\n",
    "train_data = {\n",
    "    'tokens': train_tokens,\n",
    "    'tag': train_tags,\n",
    "    'tag_id': train_tag_id,\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    'tokens': test_tokens,\n",
    "    'tag': test_tags,\n",
    "    'tag_id': test_tag_id,\n",
    "}\n",
    "\n",
    "validation_data = {\n",
    "    'tokens': val_tokens,\n",
    "    'tag': val_tags,\n",
    "    'tag_id': val_tag_id,\n",
    "}\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(validation_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "whole_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "whole_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels in int\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"tag_id\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"J1mb0o/bert-finetuned-ner-noval\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = whole_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=whole_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_val_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2tag,\n",
    "    label2id=tag2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "label_names = list(tag2id.keys())\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "metric.compute(predictions=[all_predictions], references=[all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [\"16\", \"32\"]\n",
    "learning_rate = [\"1e-5\", \"3e-5\", \"5e-5\"]\n",
    "\n",
    "for b in batch_size:\n",
    "    for lr in learning_rate:\n",
    "        model_checkpoint = f\"J1mb0o/bert-finetuned-batch{b}-lr{lr}\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "        data_collator = DataCollatorForTokenClassification(\n",
    "            tokenizer=tokenizer, return_tensors=\"tf\"\n",
    "        )\n",
    "        model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "            model_checkpoint,\n",
    "            id2label=id2tag,\n",
    "            label2id=tag2id,\n",
    "        )\n",
    "\n",
    "        print(f\"batch_size: {b}, learning_rate: {lr}\")\n",
    "        print(model_checkpoint)\n",
    "\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        for batch in tf_test_dataset:\n",
    "            logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            predictions = np.argmax(logits, axis=-1)\n",
    "            for prediction, label in zip(predictions, labels):\n",
    "                for predicted_idx, label_idx in zip(prediction, label):\n",
    "                    if label_idx == -100:\n",
    "                        continue\n",
    "                    all_predictions.append(label_names[predicted_idx])\n",
    "                    all_labels.append(label_names[label_idx])\n",
    "        print(metric.compute(predictions=[all_predictions], references=[all_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we found our best model we will dive a bit more into the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf93a24a300c45b88d29198824ca4bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3c1f7d91a4488eadcec4033382fd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7308d1ca20ea40a38da4c073a2d9490c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Some layers from the model checkpoint at J1mb0o/bert-finetuned-batch16-lr3e-5 were not used when initializing TFBertForTokenClassification: ['dropout_265']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at J1mb0o/bert-finetuned-batch16-lr3e-5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J1mb0o/bert-finetuned-batch16-lr3e-5\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "model_checkpoint = f\"J1mb0o/bert-finetuned-batch16-lr3e-5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "tokenized_datasets = whole_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=whole_dataset[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
    ")\n",
    "\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_val_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2tag,\n",
    "    label2id=tag2id,\n",
    ")\n",
    "\n",
    "print(model_checkpoint)\n",
    "label_names = list(tag2id.keys())\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the labels to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_predictions[0])\n",
    "# print(tag2id[all_predictions[0]])\n",
    "\n",
    "# all_predictions_id = [tag2id[pred] for pred in all_predictions]\n",
    "# all_labels_id = [tag2id[label] for label in all_labels]\n",
    "class_id = list(tag2id.values())\n",
    "# print(class_id)\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "with open('pred.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            continue\n",
    "        predicted_labels.append(int(line))\n",
    "\n",
    "with open('label.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            continue\n",
    "        true_labels.append(int(line))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                Precision            Recall               F1                  \n",
      "O                    0.945                0.996                0.970               \n",
      "B-person             0.850                0.462                0.598               \n",
      "I-person             0.824                0.301                0.441               \n",
      "B-location           0.705                0.527                0.603               \n",
      "I-location           0.785                0.354                0.488               \n",
      "B-corporation        0.340                0.273                0.303               \n",
      "I-corporation        0.354                0.211                0.264               \n",
      "B-product            0.439                0.142                0.214               \n",
      "I-product            0.559                0.276                0.369               \n",
      "B-creative-work      0.722                0.275                0.398               \n",
      "I-creative-work      0.630                0.208                0.313               \n",
      "B-group              0.587                0.164                0.256               \n",
      "I-group              0.515                0.140                0.221               \n",
      "person               0.835                0.352                0.495               \n",
      "location             0.744                0.421                0.538               \n",
      "corporation          0.348                0.231                0.278               \n",
      "product              0.537                0.241                0.332               \n",
      "creative-work        0.655                0.224                0.334               \n",
      "group                0.545                0.150                0.235               \n",
      "\n",
      "\n",
      "micro                0.936                0.936                0.936               \n",
      "macro                0.635                0.333                0.418               \n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate_predictions(y_pred, y_true, names_dict):\n",
    "    recall = metrics.recall_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "    precision = metrics.precision_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "    \n",
    "    f1 = metrics.f1_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "\n",
    "    recall_micro = metrics.recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    recall_macro = metrics.recall_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "\n",
    "    precision_micro = metrics.precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    precision_macro = metrics.precision_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "\n",
    "    f1_micro = metrics.f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    f1_macro = metrics.f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    pers_precision = (conf_matrix[1, 1] + conf_matrix[2, 2]) / ( sum(conf_matrix[:, 1]) + sum(conf_matrix[:, 2]))\n",
    "    loc_precision = (conf_matrix[3, 3] + conf_matrix[4, 4]) / ( sum(conf_matrix[:, 3]) + sum(conf_matrix[:, 4]))\n",
    "    corp_precision = (conf_matrix[5, 5] + conf_matrix[6, 6]) / ( sum(conf_matrix[:, 5]) + sum(conf_matrix[:, 6]))\n",
    "    prod_precision = (conf_matrix[7, 7] + conf_matrix[8, 8]) / ( sum(conf_matrix[:, 7]) + sum(conf_matrix[:, 8]))\n",
    "    cw_precision = (conf_matrix[9, 9] + conf_matrix[10, 10]) / ( sum(conf_matrix[:, 9]) + sum(conf_matrix[:, 10]))\n",
    "    group_precision = (conf_matrix[11, 11] + conf_matrix[12, 12]) / ( sum(conf_matrix[:, 11]) + sum(conf_matrix[:, 12]))\n",
    "\n",
    "    pers_recall = (conf_matrix[1, 1] + conf_matrix[2, 2]) / ( sum(conf_matrix[1, :]) + sum(conf_matrix[2, :]))\n",
    "    loc_recall = (conf_matrix[3, 3] + conf_matrix[4, 4]) / ( sum(conf_matrix[3, :]) + sum(conf_matrix[4, :]))\n",
    "    corp_recall = (conf_matrix[5, 5] + conf_matrix[6, 6]) / ( sum(conf_matrix[5, :]) + sum(conf_matrix[6, :]))\n",
    "    prod_recall = (conf_matrix[7, 7] + conf_matrix[8, 8]) / ( sum(conf_matrix[7, :]) + sum(conf_matrix[8, :]))\n",
    "    cw_recall = (conf_matrix[9, 9] + conf_matrix[10, 10]) / ( sum(conf_matrix[9, :]) + sum(conf_matrix[10, :]))\n",
    "    group_recall = (conf_matrix[11, 11] + conf_matrix[12, 12]) / ( sum(conf_matrix[11, :]) + sum(conf_matrix[12, :]))\n",
    "\n",
    "    pers_f1 = 2 * pers_precision * pers_recall / (pers_precision + pers_recall)\n",
    "    loc_f1 = 2 * loc_precision * loc_recall / (loc_precision + loc_recall)\n",
    "    corp_f1 = 2 * corp_precision * corp_recall / (corp_precision + corp_recall)\n",
    "    prod_f1 = 2 * prod_precision * prod_recall / (prod_precision + prod_recall)\n",
    "    cw_f1 = 2 * cw_precision * cw_recall / (cw_precision + cw_recall)\n",
    "    group_f1 = 2 * group_precision * group_recall / (group_precision + group_recall)\n",
    "        \n",
    "    print(f\"{'Label':<20} {'Precision':<20} {'Recall':<20} {'F1':<20}\")\n",
    "    for id, tag in zip( names_dict.values(), names_dict.keys()):\n",
    "        print(f\"{tag:<20} {precision[id]:<20.3f} {recall[id]:<20.3f} {f1[id]:<20.3f}\")\n",
    "    print(f\"{'person':<20} {pers_precision:<20.3f} {pers_recall:<20.3f} {pers_f1:<20.3f}\")\n",
    "    print(f\"{'location':<20} {loc_precision:<20.3f} {loc_recall:<20.3f} {loc_f1:<20.3f}\")\n",
    "    print(f\"{'corporation':<20} {corp_precision:<20.3f} {corp_recall:<20.3f} {corp_f1:<20.3f}\")\n",
    "    print(f\"{'product':<20} {prod_precision:<20.3f} {prod_recall:<20.3f} {prod_f1:<20.3f}\")\n",
    "    print(f\"{'creative-work':<20} {cw_precision:<20.3f} {cw_recall:<20.3f} {cw_f1:<20.3f}\")\n",
    "    print(f\"{'group':<20} {group_precision:<20.3f} {group_recall:<20.3f} {group_f1:<20.3f}\")\n",
    "\n",
    "    print('\\n')\n",
    "    print(f\"{'micro':<20} {precision_micro:<20.3f} {recall_micro:<20.3f} {f1_micro:<20.3f}\")\n",
    "    print(f\"{'macro':<20} {precision_macro:<20.3f} {recall_macro:<20.3f} {f1_macro:<20.3f}\")\n",
    "\n",
    "\n",
    "evaluate_predictions(predicted_labels, true_labels, tag2id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
